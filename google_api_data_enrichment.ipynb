{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google_api_enrichment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkh2ucfc5cz6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdEt7sj-5iNY"
      },
      "source": [
        "# import the web scraping content\n",
        "chinese_title = open('chinese_titles.txt','r')\n",
        "soup = BeautifulSoup(chinese_title, \"html.parser\")\n",
        "\n",
        "# create the main dataframe\n",
        "title=[]; author=[];  publisher=[]; appearance=[]\n",
        "\n",
        "for i in soup.find_all('p'):\n",
        "  title.append(i.text)\n",
        "  author.append(i.next_sibling.text)\n",
        "  publisher.append(i.next_sibling.next_sibling.text)\n",
        "  appearance.append(i.parent.parent.next_sibling.text)\n",
        "\n",
        "df = pd.DataFrame(list(zip(title, author, publisher, appearance)))\n",
        "\n",
        "df.columns=['title','author','publisher','appearance']\n",
        "df['api'] = 'https://www.googleapis.com/books/v1/volumes?q=' + df['title'] +'+inauthor:'+df['author']"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK9jV7I2VmrV"
      },
      "source": [
        "# call google books api to retrive additional data\n",
        "lst_cat=[]; lst_des=[]; lst_pt=[]; lst_date=[]; lst_pub=[]; lst_isbn=[]\n",
        "\n",
        "for i in range(len(df)):\n",
        "  json_rs = requests.get(df['api'][i])\n",
        "  json_pd = json.loads(json_rs.text)\n",
        "  \n",
        "  try:\n",
        "    lst_cat.append(json_pd['items'][0]['volumeInfo']['categories'])\n",
        "  except KeyError:\n",
        "    lst_cat.append(np.nan)\n",
        "  \n",
        "  try:\n",
        "    lst_des.append(json_pd['items'][0]['volumeInfo']['description'])\n",
        "  except KeyError:\n",
        "    lst_des.append(np.nan)\n",
        "\n",
        "  try:\n",
        "    lst_pt.append(json_pd['items'][0]['volumeInfo']['printType'])\n",
        "  except KeyError:\n",
        "    lst_pt.append(np.nan)\n",
        "\n",
        "  try:\n",
        "    lst_date.append(json_pd['items'][0]['volumeInfo']['publishedDate'])\n",
        "  except KeyError:\n",
        "    lst_date.append(np.nan)\n",
        "\n",
        "  try:\n",
        "    lst_pub.append(json_pd['items'][0]['volumeInfo']['publisher'])\n",
        "  except KeyError:\n",
        "    lst_pub.append(np.nan)\n",
        "\n",
        "  try:\n",
        "    lst_isbn.append(json_pd['items'][0]['volumeInfo']['industryIdentifiers'][0]['identifier'])\n",
        "  except KeyError:\n",
        "    lst_isbn.append(np.nan)\n",
        "\n",
        "# create the api dataframe\n",
        "df_api = pd.DataFrame(list(zip(lst_cat, lst_des, lst_pt, lst_date, lst_pub, lst_isbn)))\n",
        "df_api.columns=['category','description','pub_type','pub_date','publisher_v','isbn']"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIdT7z2J7hmH"
      },
      "source": [
        "# merge dataframes\n",
        "df_merge = df.join(df_api, how='outer')\n",
        "df_merge.to_csv('df_merge.csv')"
      ],
      "execution_count": 58,
      "outputs": []
    }
  ]
}